{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "332cd070",
   "metadata": {},
   "source": [
    "# Web Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab7438",
   "metadata": {},
   "source": [
    "# collect from 1 Jan 2016 to 31 Dec 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d73a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "def createRequest(url, page, from_date, to_date):\n",
    "\n",
    "    params = {\n",
    "        'order': 'asc',\n",
    "        'site': 'stackoverflow',   \n",
    "        'filter': '!T1gn2_YmiRkEHaO(cX',\n",
    "        'key': '8hvLA7uVPEIp6wwaqNOF5w((',\n",
    "        'pagesize': '100',\n",
    "        'page': page,\n",
    "        'sort': 'creation',\n",
    "        'fromdate': from_date,\n",
    "        'todate': to_date\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\n",
    "            \"GET\",\n",
    "            url,\n",
    "            params = params\n",
    "        )\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        print(\"ERROR: {}\".format(e))\n",
    "\n",
    "    json_data = json.loads(response.text)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "    from_date = \"1451606400\" # Jan 1, 2016\n",
    "    to_date = \"1451692800\" # Jan 2, 2016\n",
    "    page = 1\n",
    "    sum_of_questions = 0\n",
    "    days = 366\n",
    "    count_day = 0\n",
    "    \n",
    "    while not count_day == days:\n",
    "        print(\"\\nPage: {} From: {} To: {}\".format(page, from_date, to_date))\n",
    "        print(\"send request ...\")\n",
    "        res = createRequest(url, page, from_date, to_date)\n",
    "        print(\"# questions in the page: \", len(res['items']))\n",
    "\n",
    "        json_file = 'C:/Users/arisa/StackOverflow-Project/questions/2016/{:03d}.json'.format(count_day + 1)\n",
    "        print(\"dump {} ...\".format(json_file))\n",
    "        with open(json_file, 'w') as json_f:\n",
    "            json.dump(res, json_f, indent=4)\n",
    "\n",
    "        sum_of_questions += len(res['items'])\n",
    "        print(\"total of questions: \", sum_of_questions)\n",
    "        from_date = to_date\n",
    "        orig = datetime.datetime.fromtimestamp(int(to_date))\n",
    "        to_date = orig + datetime.timedelta(days=1)\n",
    "        to_date = str(int(to_date.timestamp()))\n",
    "        count_day += 1\n",
    "        page += 1\n",
    "        if page > 5:\n",
    "            page = 1\n",
    "        if count_day == 150:\n",
    "            time.sleep(20)\n",
    "            continue\n",
    "        time.sleep(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580a47c",
   "metadata": {},
   "source": [
    "# collect from 1 Oct 2017 to 31 Dec 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "def createRequest(url, page, from_date, to_date):\n",
    "\n",
    "    params = {\n",
    "        'order': 'asc',\n",
    "        'site': 'stackoverflow',\n",
    "        'filter': '!T1gn2_YmiRkEHaO(cX',\n",
    "        'key': '8hvLA7uVPEIp6wwaqNOF5w((',\n",
    "        'pagesize': '100',\n",
    "        'page': page,\n",
    "        'sort': 'creation',\n",
    "        'fromdate': from_date,\n",
    "        'todate': to_date\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\n",
    "            \"GET\",\n",
    "            url,\n",
    "            params = params\n",
    "        )\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        print(\"ERROR: {}\".format(e))\n",
    "\n",
    "    json_data = json.loads(response.text)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "    from_date = \"1506816000\" # Oct 1, 2017\n",
    "    to_date = \"1506902400\" # Oct 2, 2017\n",
    "    page = 1\n",
    "    sum_of_questions = 0\n",
    "    days = 92 + 273\n",
    "    count_day = 273\n",
    "\n",
    "    while not count_day == days:\n",
    "        print(\"\\nPage: {} From: {} To: {}\".format(page, from_date, to_date))\n",
    "        print(\"send request ...\")\n",
    "        res = createRequest(url, page, from_date, to_date)\n",
    "        print(\"# questions in the page: \", len(res['items']))\n",
    "\n",
    "        json_file = 'C:/Users/arisa/StackOverflow-Project/questions/2017/{:03d}.json'.format(count_day + 1)\n",
    "        print(\"dump {} ...\".format(json_file))\n",
    "        with open(json_file, 'w') as json_f:\n",
    "            json.dump(res, json_f, indent=4)\n",
    "\n",
    "        sum_of_questions += len(res['items'])\n",
    "        print(\"total of questions: \", sum_of_questions)\n",
    "        from_date = to_date\n",
    "        orig = datetime.datetime.fromtimestamp(int(to_date))\n",
    "        to_date = orig + datetime.timedelta(days=1)\n",
    "        to_date = str(int(to_date.timestamp()))\n",
    "        count_day += 1\n",
    "        page += 1\n",
    "        if page > 5:\n",
    "            page = 1\n",
    "        if count_day == 150:\n",
    "            time.sleep(20)\n",
    "            continue\n",
    "        time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da009e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data collection\n",
    "# send request for 100 first questions created in Jan 1, 2013\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import calendar\n",
    "\n",
    "def DateToStr(date):\n",
    "    return str(calendar.timegm(date.utctimetuple()))\n",
    "\n",
    "def nextDate(date):\n",
    "    next_date = date + datetime.timedelta(days = 1)\n",
    "    return next_date\n",
    "\n",
    "def createRequest(url, page, from_date, to_date):\n",
    "\n",
    "    params = {\n",
    "        'order': 'asc',             # ascending order\n",
    "        'site': 'stackoverflow',    # stackoverflow site\n",
    "        'filter': '!T1gn2_YmiRkEHaO(cX',    # use this filter only\n",
    "        'key': '8hvLA7uVPEIp6wwaqNOF5w((',  # API key\n",
    "        'pagesize': '100',          # max page size\n",
    "        'page': page,               # page number\n",
    "        'sort': 'creation',         # sort questions by creation date\n",
    "        'fromdate': from_date,      # from date\n",
    "        'todate': to_date           # to date\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\n",
    "            \"GET\",\n",
    "            url,\n",
    "            params = params\n",
    "        )\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        print(\"ERROR: {}\".format(e))\n",
    "\n",
    "    json_data = json.loads(response.text)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # API URL\n",
    "    url = \"https://api.stackexchange.com/2.3/questions\"\n",
    "    start = 3\n",
    "    current_date = datetime.datetime(2015, 1, 1, 0, 0, 0) + datetime.timedelta(days = start-1)\n",
    "    \n",
    "    for i in range(start, 32):\n",
    "        \n",
    "        from_date = DateToStr(current_date)\n",
    "        to_date = DateToStr(nextDate(current_date))\n",
    "        page = 1\n",
    "        \n",
    "        print(current_date, nextDate(current_date))\n",
    "        print(\"\\nsend request ...\")\n",
    "        res = createRequest(url, page, from_date, to_date)\n",
    "        print(\"# questions in the page: \", len(res[\"items\"]))\n",
    "        \n",
    "        # dump json file\n",
    "        json_file = str(i).zfill(3) + \".json\"\n",
    "        print(\"dump {} ...\".format(json_file))\n",
    "        with open(json_file, \"w\") as json_f:\n",
    "            json.dump(res, json_f, indent = 4)\n",
    "            \n",
    "        time.sleep(10)\n",
    "        current_date = nextDate(current_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "alltag = pd.read_csv(\"C:/Users/arisa/StackOverflow-Project/dataset/all_tags.csv\")\n",
    "\n",
    "def createRequest(url, pag, combined_tags):\n",
    "\n",
    "    params = {\n",
    "        'order': 'asc',\n",
    "        'filter': '!T1gn2_YmiRkEHaO(cX',\n",
    "        'key': '8hvLA7uVPEIp6wwaqNOF5w((',\n",
    "        'pagesize': '20',\n",
    "        'page': page,\n",
    "        'sort': 'creation',\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.request(\n",
    "            \"GET\",\n",
    "            url,\n",
    "            params = params\n",
    "        )\n",
    "    except requests.exceptions.RequestException as e:  \n",
    "        print(\"ERROR: {}\".format(e))\n",
    "\n",
    "    json_data = json.loads(response.text)\n",
    "\n",
    "    return json_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    url = \"https://api.stackexchange.com/docs/wikis-by-tags\"\n",
    "    page = 1\n",
    "    sum_of_tags = 0\n",
    "    combined_tags = set()\n",
    "    for i in range(len(alltag[\"tags\"])):\n",
    "      dupall = [x.strip(\"\\''\") for x in alltag[\"tags\"][i].strip( '][' ).split( ', ' )]\n",
    "      for dup in dupall:\n",
    "        combined_tags.add(dup)\n",
    "\n",
    "    combined_tags = sorted(list(combined_tags))\n",
    "        \n",
    "    res = createRequest(url, page, combined_tags)\n",
    "    print(\"# tags in the page: \", len(res['items']))\n",
    "\n",
    "    #json_file = 'C:/Users/arisa/StackOverflow-Project/duplicatetag/tagname{}.json'\n",
    "    #json_file = str(i).zfill(3) + \".json\"\n",
    "    json_file = '/content/json'\n",
    "    print(\"dump {} ...\".format(json_file))\n",
    "    print(\"dump {} ...\".format(json_file))\n",
    "    with open(json_file, 'w') as json_f:\n",
    "      json.dump(res, json_f, indent=4)\n",
    "\n",
    "    sum_of_tags += len(res['items'])\n",
    "    print(\"total of tags: \", sum_of_tags)\n",
    "              \n",
    "time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb43455",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
